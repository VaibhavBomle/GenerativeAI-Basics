{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6f3e9bb5-5fdd-486e-9ed6-81979e7fa970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing openai library\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "79b6cf08-289d-480b-bb24-43e8a5eea545",
   "metadata": {},
   "outputs": [],
   "source": [
    "mykey = 'YOUR_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "97f6b204-5b69-47f8-94f2-3c36d7c2be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = mykey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a912a8c2-4697-4c72-bd20-21b337471251",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: YOUR_API_KEY. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m all_models \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\testingopenai\\lib\\site-packages\\openai\\resources\\models.py:79\u001b[0m, in \u001b[0;36mModels.list\u001b[1;34m(self, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlist\u001b[39m(\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m     74\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SyncPage[Model]:\n\u001b[0;32m     75\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    Lists the currently available models, and provides basic information about each\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;124;03m    one such as the owner and availability.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_api_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/models\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSyncPage\u001b[49m\u001b[43m[\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\testingopenai\\lib\\site-packages\\openai\\_base_client.py:1249\u001b[0m, in \u001b[0;36mSyncAPIClient.get_api_list\u001b[1;34m(self, path, model, page, body, options, method)\u001b[0m\n\u001b[0;32m   1238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_api_list\u001b[39m(\n\u001b[0;32m   1239\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1240\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1246\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1247\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SyncPageT:\n\u001b[0;32m   1248\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m-> 1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_api_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\testingopenai\\lib\\site-packages\\openai\\_base_client.py:1094\u001b[0m, in \u001b[0;36mSyncAPIClient._request_api_list\u001b[1;34m(self, model, page, options)\u001b[0m\n\u001b[0;32m   1090\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\n\u001b[0;32m   1092\u001b[0m options\u001b[38;5;241m.\u001b[39mpost_parser \u001b[38;5;241m=\u001b[39m _parser\n\u001b[1;32m-> 1094\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\testingopenai\\lib\\site-packages\\openai\\_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\testingopenai\\lib\\site-packages\\openai\\_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    977\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    979\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m    983\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    984\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    987\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    988\u001b[0m )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: YOUR_API_KEY. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "all_models = openai.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846857ed-5ee0-4598-b49c-0915bbd4a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40af4b48-3610-4045-b97c-b6f379b50718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(list(all_models),columns=[\"id\",\"created\",\"object\",\"owned_by\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903d0044-3ba7-4808-b0d3-bfbc9730aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat completion API and function calling\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = mykey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03a47e-320e-439e-a8f5-b9b6b78fccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model = \"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"How  i can start my business?\"\n",
    "    }\n",
    "  ]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a4755-13d6-4a1f-b2e8-c49e627e8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64640d92-8e8e-432a-86d3-9e06ea7bc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f62fca8-5ed7-49d5-a5e9-b14a5cdc7081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23107a6-173e-44ee-8197-afc855a9ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_Description = \"John is a student of IIT Delhi. He has a score of 9.5 GPA. He has a good programmin skills and is an active member of the colleges AI Club \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5d878a-e289-422d-b2ae-603ea2a5ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb190a95-5b57-4b23-b135-852283988277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple prompt to extract information from \"student_desription\" in a JSON format.\n",
    "\n",
    "prompt = f'''\n",
    "Please extract the following information rom the iven text and return it as JSON Object :\n",
    "\n",
    "name\n",
    "college\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "(student_Description)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d1424d-190c-4e68-a464-d6893b22cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d97436b-1abe-4f31-87a1-6e3dbfe4024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=mykey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69307a77-3bf5-4ac3-8e67-fd1999badc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe3e948-04b3-4415-820c-dd4d9ca4832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model = \"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": prompt\n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2627fd56-a00b-4a35-842d-ca59ba446ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4befc0b5-0e9c-443a-a016-9c408bed5e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88f76c1-d83a-483c-9f85-81ab24250918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.load(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1500cf39-ff73-4f06-ab2a-c6ec0ac60e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_custom_function = [\n",
    "  {\n",
    "    \"name\": \"extract_student_info\",\n",
    "    \"description\": \"Get the student information from the body of the input text \",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"name\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"Name of the persion.\"\n",
    "        },\n",
    "        \"college\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"The college name.\"\n",
    "        },\n",
    "        \"grades\": {\n",
    "          \"type\": \"integer\",\n",
    "          \"description\": \"CGPA of the Student.\"\n",
    "        },\n",
    "        \"club\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"College club for extracurricular activities.\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784acea4-b890-4c75-aa94-26f0428ea9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = {\"role\": \"user\", \"content\": prompt},\n",
    "    functions = student_custom_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0384d103-4a26-43a6-af7f-3c0a791fb31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa0be33-2512-4e74-b6d4-2a3f2c613fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2.choice[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11b179a-0a0d-49ff-b551-10e7d56b7c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2.choice[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95735dd-0c97-4db3-b10d-766ec031d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(response2.choice[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516bb2a-436d-4494-9d66-efbf80ab60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(json.loads(response2.choice[0].message.function_call.arguments) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c74690-ea76-4f3a-ae0e-26f423aa7375",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_Description_two = \"Hobert is a student of IIT Mumbai. He has a score of 9.5 GPA. He has a good programmin skills and is an active member of the colleges AI Club \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6524545d-3dc9-48d7-96eb-bab86faab3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_Description_two = \"Kevin is a student of IIT Roorkee. He has a score of 9.5 GPA. He has a good programmin skills and is an active member of the colleges AI Club \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc3a648-7e64-41ef-94b1-9c68d710dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_info = [student_Description, student_Description_two,student_Description_two]\n",
    "\n",
    "for student n student_info:\n",
    "  response = client.chat.completions.create(\n",
    "      model = 'gpt-3.5-turbo',\n",
    "      messages = [{'role': 'user', 'content': student}],\n",
    "      functions = student_custome_function,\n",
    "      function_call = 'auto'\n",
    "  )\n",
    "\n",
    "  response = json.loads(response.choices[0].message.function_call.arguments)\n",
    "  print(response) # import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bf3f08-5c14-4bae-8fc6-185b00e50f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can call multple function\n",
    "# student_info = [student_Description, student_Description_two,student_Description_two]\n",
    "# function = [student_custiom_function_one,student_custom_function_two]\n",
    "# for student n student_info:\n",
    "#   response = client.chat.completions.create(\n",
    "#       model = 'gpt-3.5-turbo',\n",
    "#       messages = [{'role' : 'user', 'content': student}],\n",
    "#       functions = function,\n",
    "#       function_call = 'auto'\n",
    "#   )\n",
    "\n",
    "#   response = json.loads(response.choices[0].message.function_call.arguments)\n",
    "#   print(response)  # import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1105eea-800a-47da-b3c9-23c108374c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\" : \"user\",\n",
    "            \"content\": \"When's the next light from Delhi to Mumbai?\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25a26cf-f9a8-470e-9258-2c5641c26cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfebfc4-ac42-418f-be2f-233bedec8b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advance function calling\n",
    "function_description = [\n",
    "    {\n",
    "  \"name\": \"get_flight_info\",\n",
    "  \"description\": \"Get flight information between two locations\",\n",
    "  \"parameters\": {\n",
    "    \"type\": \"objects\",\n",
    "    \"propeties\": {\n",
    "      \"loc_origin\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The departure airport , e.g DEL\"\n",
    "      },\n",
    "      \"loc_destination\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The destination airport , e.g MUM\"\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\"loc_origin\", \"loc_destination\"]\n",
    "  }\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c3a53b-0584-4113-8797-dc64590036c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_propmpt = \"When's the ext flight from new delhi to mumbai ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f44726a-5245-407f-a156-ad0925ba3f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\": user_prompt\n",
    "        }\n",
    "    ],\n",
    "    # Add function calling\n",
    "    function = function_descriptions,\n",
    "    function_call = \"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937bd92d-401a-4307-9792-516f20e69a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f816632-10d6-48ac-95e9-72ae871c8bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1681fa5-b717-49ab-8549-056ecfb89cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3d020f-87e0-4be6-9f1b-1ae8803b1cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  suppose this function calling third party API to get flight details\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_flight_info(loc_origin,loc_destination):\n",
    "    \"\"\"Get flight information between two locations.\"\"\"\n",
    "\n",
    "# Example output returned from an API or database\n",
    "  flight_info ={\n",
    "      \"loc_origin\" : loc_origin,\n",
    "      \"loc_destination\" : loc_Destination,\n",
    "      \"datetie\" : str(datetime.now() + timedelta(hours=2)),\n",
    "      \"airline\" : \"KLM\",\n",
    "      \"flight\" : \"KL643\"\n",
    "  }\n",
    "  return json.dumps(flight_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2922ae95-5a3e-4f1d-bc8a-ba539d1b4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(response2.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628d76f9-5143-4a40-a80c-206ff46bdf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = json.loads(response2.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4e502d-d336-4457-8c5c-22c5b5dedd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407350d-6175-4e10-b8eb-c9a0adac6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = json.loads(response2.choices[0].message.function_call.arguments).get(\"loc_origin\")\n",
    "=destination = json.loads(response2.choices[0].message.function_call.arguments).get(\"loc_destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f51560b-9c9d-41f5-b430-0fc8aaaa5708",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2.choices[0].message.function_call.name  #  function name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaf22ab-b370-40a8-8b83-58d2cc6b32eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response2.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245e032-3cdb-4848-b7bc-162e1b2cd68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(response2.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aaee5f-55c0-41df-8fbd-58d144667299",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bda2b6-2930-4faa-8b85-93ceaad08f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(eval(\"2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88d66d2-cfe2-40b1-a2e5-fc3d58653b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_function = eval(response2.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be82e5-dda0-4ea9-b2d7-62234789aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight = chosen_function(**params)\n",
    "print(flight) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d28149-d326-435a-8fc9-27dcb0783af4",
   "metadata": {},
   "source": [
    "response3 = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        {\"roles\": \"user\", \"content\":user_promt},\n",
    "        {\"role\": \"function\", \"name\": response2.choices[0].message.function_call.name, \"content\": flight}\n",
    "    ],\n",
    "    \n",
    "    # Add function calling\n",
    "    functions = fuction_description,\n",
    "    function_call = \"auto\"  # specify the function call\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372cf005-5ca8-48b1-8c94-159a775b1cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f5775-54bf-471f-b404-352b432aced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e758258-aed0-4afe-afbc-346dcb2ea134",
   "metadata": {},
   "outputs": [],
   "source": [
    "response3.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6837e7cd-a280-4d8b-be98-c8cd9883a60a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ffa87-ace0-4737-95e8-f56bb1b6ce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function calling --> Learn how to connect large language models to exteral tools. It is a wrapper of top of AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb740e5-c0de-4391-b607-ce2708b8cd38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b0363d-76cd-49cb-b911-d28b1845e7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "04a2b072-816d-45c4-a30b-0dd95e9c0f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0640f339-0abe-4088-8b76-72aa6fd8b5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c79d1a-50cc-45c4-b906-c14aeaa226e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(openai_api_key=mykey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb4d5c6-a3c8-4df6-bb82-a561c62c5048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero shot prompting\n",
    "prompts = \"Can you tell me the total number of countries in Asia? can you give me the top 50 country names?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8eb9eb-f509-4e5d-a244-a59a3b3c9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.predict(prompt).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb5281f-d881-4bc0-b9a8-dee111235ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero shot prompting\n",
    "prompt2 = \"can you tell me a captial of india?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e93dd-c371-48d3-b272-bf9e67c390eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.predict(prompt2).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fcc17f-b45a-4dd0-b22b-9f8b71ef2052",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = \"what exalty tokens, vector ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162752b3-f008-4a25-8477-dce2e20557a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.predict(prompt3).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183883c8-e266-4b50-8527-c56520645926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Templates :\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e4b68a-0d68-4bf2-b8c0-7035b8d166ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_tempate_name = PromptTemplate(\n",
    "    input_variable = [\"country\"]\n",
    "    template = \"can you tell me the capital of {country}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a177dca-ba37-40f9-958c-f7405ab19ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name.format(country= \"delhi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f00f3e-9fe6-444e-9f70-806e97bb0a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name.format(country= \"china\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5391d1f-6a7e-4343-83d3-eeb63368316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=prompt_template_name.format(country=\"delhi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10aecc-abc3-48ef-92a1-dc251c803231",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=prompt_template_name.format(country=\"china\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ad978-31f9-490c-885c-819397190b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.predict(prompt1).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd236641-20bb-4c6a-a7ef-2b93e210c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.predict(prompt2).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad052d2b-dc26-4e71-8cf4-23ed8ef5b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that akes a {product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25383de2-8a9d-4b30-a775-8f8cb050304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = prompt.format(product = \"toys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44623729-6966-4297-9029-f451555d909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.predict(prompt3).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae61bbb9-7b3d-4884-9aa7-199e213bd3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fd6d81-a542-4c6c-9a6b-9063346811b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent in langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25584f89-03d5-4210-8f8d-87b531103cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt4 = \"Can you tell me who wont the recent cricket world cup?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f202e15-2892-409b-84f4-c4e84bf69ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.predict(prompt4).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746db21-e770-43b2-9e9a-732bd374edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt5 = \"Can you tell me current GDP of India?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197b2ffe-ca86-45d4-99dd-a0b8b7a74761",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.predict(prompt5).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8c5db0-9013-45c9-bb7d-66f13a7d012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for extracting a real time info I am going to user serp api\n",
    "# now by using this serp api I will call google-search-engin\n",
    "# and I will extract the information in a real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28942bc-583f-426e-b3be-e66d2737a1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e9b20e-adc8-4bca-8f16-69d521758827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install google search library in current vertual env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1abf006b-1476-40de-b620-7adc3822fa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\acer\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-search-results) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->google-search-results) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->google-search-results) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->google-search-results) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->google-search-results) (2024.2.2)\n",
      "Building wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (setup.py): started\n",
      "  Building wheel for google-search-results (setup.py): finished with status 'done'\n",
      "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32077 sha256=385452dbe074a961e6443a5a2036ecfc1d3948ce046a52cfadbcfdf821866bc0\n",
      "  Stored in directory: c:\\users\\acer\\appdata\\local\\pip\\cache\\wheels\\d3\\b2\\c3\\03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "065d5cfc-721c-4cea-8295-6c0b6ee3adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  api to access Google search Engine \n",
    "# Get API Key from ----> https://serpapi.com/manage-api-key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b3ed243e-e923-4356-b4dc-cb811b76b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "from langchain.llms import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb9f993-2bd7-4604-846f-48374969dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(openai_api_key=mykey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e9c2c-ad9d-4a26-b133-0cd73bbaf407",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = load_tools([\"serpapi\"],serpapi_api_key=serpapi_key,llm=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c823de-c41d-4d2e-b152-5f391be5cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=initialize_agent(tool,client,agent=AgentType.ZERO_SHOT_rEACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834cf37f-9cc2-47d0-bca7-72a1e5d6a4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"Can you tell who won the cricekt worldcup recently\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a772df8-8d32-46ed-8ea5-202543dd3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"Can you tell me top 10 current affairs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2f86224-143b-45ea-9e51-0de09b81a8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\acer\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\acer\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\acer\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11704 sha256=12a884503c43efc0512233b8ed0125aba1f8313b51f7bb7c13cd60e9e359d030\n",
      "  Stored in directory: c:\\users\\acer\\appdata\\local\\pip\\cache\\wheels\\5e\\b6\\c5\\93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "429a4e77-0585-4850-a246-e02504dd987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = load_tools([\"wikipedia\"],llm=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a9317c8b-a48a-4fdc-aeb4-551aa889f825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\envs\\testingopenai\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for LLMChain\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m agent\u001b[38;5;241m=\u001b[39m\u001b[43minitialize_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAgentType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZERO_SHOT_REACT_DESCRIPTION\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\testingopenai\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     emit_warning()\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\testingopenai\\lib\\site-packages\\langchain\\agents\\initialize.py:67\u001b[0m, in \u001b[0;36minitialize_agent\u001b[1;34m(tools, llm, agent, callback_manager, agent_path, agent_kwargs, tags, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     agent_cls \u001b[38;5;241m=\u001b[39m AGENT_TO_CLASS[agent]\n\u001b[0;32m     66\u001b[0m     agent_kwargs \u001b[38;5;241m=\u001b[39m agent_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m---> 67\u001b[0m     agent_obj \u001b[38;5;241m=\u001b[39m agent_cls\u001b[38;5;241m.\u001b[39mfrom_llm_and_tools(\n\u001b[0;32m     68\u001b[0m         llm, tools, callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39magent_kwargs\n\u001b[0;32m     69\u001b[0m     )\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m agent_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     agent_obj \u001b[38;5;241m=\u001b[39m load_agent(\n\u001b[0;32m     72\u001b[0m         agent_path, llm\u001b[38;5;241m=\u001b[39mllm, tools\u001b[38;5;241m=\u001b[39mtools, callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager\n\u001b[0;32m     73\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\testingopenai\\lib\\site-packages\\langchain\\agents\\mrkl\\base.py:112\u001b[0m, in \u001b[0;36mZeroShotAgent.from_llm_and_tools\u001b[1;34m(cls, llm, tools, callback_manager, output_parser, prefix, suffix, format_instructions, input_variables, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tools(tools)\n\u001b[0;32m    105\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_prompt(\n\u001b[0;32m    106\u001b[0m     tools,\n\u001b[0;32m    107\u001b[0m     prefix\u001b[38;5;241m=\u001b[39mprefix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39minput_variables,\n\u001b[0;32m    111\u001b[0m )\n\u001b[1;32m--> 112\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m \u001b[43mLLMChain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m tool_names \u001b[38;5;241m=\u001b[39m [tool\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools]\n\u001b[0;32m    118\u001b[0m _output_parser \u001b[38;5;241m=\u001b[39m output_parser \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_default_output_parser()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\testingopenai\\lib\\site-packages\\langchain_core\\load\\serializable.py:120\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\testingopenai\\lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 2 validation errors for LLMChain\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)"
     ]
    }
   ],
   "source": [
    "agent=initialize_agent(tool,client,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8459416b-96fe-4de2-b24c-d2cc83636951",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you tell me What is the current GDP of USA?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "agent.run(\"Can you tell me What is the current GDP of USA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "179aacad-178e-4904-9421-21a0df40ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Chain  -- > Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. The primary supported way to do this is with LCEL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d41275-40bd-4a3e-8e4d-4886848f7857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f434a03-a874-424f-800c-1f8e3ed7a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchin.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromtTemplate.from_templte(\"What is the good name of company that makes {product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ae244b-811b-464b-9e84-20b77137fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948294d4-02e8-42f4-b8f8-36bdf1ee785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMChain(llm = client,prompt = prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45020bf4-7469-46a4-bfda-545990233248",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.run(\"Wine\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a35b7-6e05-4044-810e-16e404243142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bfd460-efdf-4225-973f-75cac4a16b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromtTemplate(\n",
    "    input_variable = ['cuisine'],\n",
    "    template = \"i want to open a restaurent for {cuisine} food, suggest a fency name fo this\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1507442-c4c6-4cbb-8fd4-0cbe408f9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bfd97f-535c-4ccd-9dcb-573bd2191106",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=client, prompt=propt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6f31c0-c9f3-4cf2-a146-39758f4c1f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"chinese\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e08852-9928-4390-9838-ac0bf14c8d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"indian\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca4e23-66ab-4970-8b4a-a76b7786027a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e56d39-6b60-4989-bb31-d06075f3afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to combine multiple chain and set a sequence for that we use simple sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bac72434-457e-4ce0-8f8e-a85b7ba329e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3044996317.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[86], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    template =\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# first template\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = [\"startup_name\"],\n",
    "    template =  \"I want to start a startup for {startup_name} , suggest me a good name for this\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939b09c-2f5c-410a-ac6e-b230ac014e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_chain = LLMChain(llm=client,prompt_template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b711c782-3672-4844-945a-843da5db9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second template\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = [\"name\"],\n",
    "    template =  \"suggest some strategies for {name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af75c530-3534-4387-b081-0f9e7e597e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies_chain = LLMChain(llm=client,prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886db074-3cb7-4055-957e-ade10948f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = SimpleSequentialChain(chains=[name_chain,strategies_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84865886-2bf4-4d8a-8e63-8827f03d7cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"Artificial intelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89418b8a-7fe7-4c5e-82c7-ca1266eaf951",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.run(\"Artificial intelligence\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02bff22-f841-4d51-b9d2-88f33d6ca152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff8c7d-d2b1-4cc7-91e7-36cfb769fb21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b392b-dd6e-4a34-862a-5c7f0f204f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca154b-cfb5-4b8e-a109-ec693e9a42b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = [\"cuisine\"],\n",
    "    template =  \"I want to open a restaurant for {cuisine}, suggest a fency name for it\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=client,prompt_template_name,output_key=\"restaurant_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96f03bd-6795-4a4e-9901-ec6c44fe1631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_templates_items =  PromptTemplate(\n",
    "    input_variables = [\"restaurant_name\"],\n",
    "    template =  \"suggest some menu items for {restaurant_name}\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm=client,prompt_template_name,output_key=\"menu_ittems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8999a9f-8d9c-4b62-b02e-e1e0d05df9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f83df46-7273-474d-a3fb-639c6ed778f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain =SequentialChain(\n",
    "    chains=[name_chain,food_items_chain],\n",
    "    input_variables = [\"cuisine\"],\n",
    "    output_variables = [\"restaurant_name\",\"menu_ittems\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4589dc-9f0a-4cd5-86fa-a78e3cb9eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain({\"cuisine\":\"indian\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d7795-9289-4b7b-9a63-869c18058296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5281172a-a242-497f-98a9-4e1dad1ff937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-4.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Downloading pypdf-4.0.2-py3-none-any.whl (283 kB)\n",
      "   ---------------------------------------- 0.0/284.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/284.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/284.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/284.0 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 30.7/284.0 kB 435.7 kB/s eta 0:00:01\n",
      "   ---- ---------------------------------- 30.7/284.0 kB 435.7 kB/s eta 0:00:01\n",
      "   ---- ---------------------------------- 30.7/284.0 kB 435.7 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 92.2/284.0 kB 403.5 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 92.2/284.0 kB 403.5 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 92.2/284.0 kB 403.5 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 143.4/284.0 kB 387.0 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 194.6/284.0 kB 454.0 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 276.5/284.0 kB 607.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- 284.0/284.0 kB 583.6 kB/s eta 0:00:00\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-4.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e5690e20-7bb9-4574-9902-36e2604a7caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136da69-af61-4a26-90a5-5edc87f59b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(r\"C:\\Users\\ACER\\Downloads\\CRN7959819946.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b8a233-1c69-48df-abaa-fbd5576a6a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feba3138-744d-4d49-b7d3-0286c62d2e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
