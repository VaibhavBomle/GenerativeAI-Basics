# -*- coding: utf-8 -*-
"""MemoryInLangChain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JT8DKy0-IdsvYEeYaX-alP9CEHELNhIh

**Memory**
"""

!pip install langchain

from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.llms import OpenAI
from google.colab import userdata
OPENAI_API_KEY = userdata.get('OPEN_API_KEY')  # using OpenAI

client = OpenAI(openAI_api_key=OPENAI_API_KEY)

prompt_template_name = PromptTemplate(
    input_variables= ['product'],
    template = "What is a good name for a company that makes {product}"
)

chain = LLMChain(llm = client,prompt = prompt_template_name)

print(client.run("Colourful cup").strip())

prompt_template_name = PromptTemplate(
    input_variables= ['product'],
    template = "What is a good name for a company that makes {product}"
)

chain = LLMChain(llm = client,prompt = prompt_template_name)

chain.run("drons").strip()

chain.memory

type(chain.memory)

"""**ConversationBufferMemory**

**We can attach memory to remember all previous conversation**
"""

from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()

prompt_template_name = PromptTemplate(
    input_variables= ['product'],
    template = "What is a good name for a company that makes {product}"
)

chain = LLMChain(llm=client,prompt=prompt_template_name, memory = memory)

chain.run("wines")

chain.run("Camera")

chain.run("Drons")

chain.memory

print(chain.memory.buffer)



"""**ConversationChain**

Conversation buffer memory goes growing endlessly
"""

from langchain.chains import ConversationChain

convo = ConversationChain(llm=OpenAI(openai_api_key=OPENAI_KEY,temperature = 0.7))

convo.prompt

convo.run("Who won the first cricket worldcup ?")

convo.run("Can you tell how much 6+5 ?")

convo.run("Can you tell how much 5+3 ?")

convo.run("Who was the captain of the winning team ?")

"""**ConversationBufferWindowMemory**"""

from langchain.memory import ConversationBufferWindowMemory

memory = ConversationBufferWindowMemory(k=1)

convo = ConversationChain(llm=OpenAI(openai_api_key=OPENAI_KEY,temperature = 0.7),memory=memory)

convo.run("Who won the first cricket worldcup ?")

convo.run("Can you tell how much 6+5 ?")

convo.run("Can you tell how much 5+3 ?")

convo.run("Who was the captain of the winning team ?")